# ğŸš€ AI Document Intelligence System (LLM + RAG)

> Voice-enabled AI system that lets you chat with your documents using Local LLM + Retrieval-Augmented Generation (RAG).

---

## ğŸ§  Overview

AI Document Intelligence System is a full-stack AI application that allows users to:

- ğŸ“„ Upload PDF / DOCX / TXT documents  
- ğŸ’¬ Ask questions about the document  
- ğŸ¤ Use voice input  
- ğŸ”Š Receive voice responses  
- âš¡ Get answers powered by Retrieval-Augmented Generation (RAG)  
- ğŸ’¾ Persist vector database locally  

Built using **FastAPI + Streamlit + LangChain + FAISS + HuggingFace Models**

---

## ğŸ— Architecture

```
User (Voice/Text)
        â†“
Streamlit Frontend
        â†“
FastAPI Backend
        â†“
RAG Engine
        â†“
FAISS Vector Store
        â†“
HuggingFace LLM + Embeddings
```

---

## âš™ï¸ Tech Stack

### ğŸ–¥ Backend
- FastAPI
- LangChain
- FAISS (Vector Database)
- HuggingFace Transformers
- Sentence Transformers
- PyPDF2
- python-docx

### ğŸ¨ Frontend
- Streamlit
- SpeechRecognition
- pyttsx3 (Text-to-Speech)

### ğŸ§  Models
- **Embeddings:** `sentence-transformers/all-MiniLM-L6-v2`
- **LLM:** `google/flan-t5-small`

---

## ğŸ“¦ Features

- âœ… Multi-format Document Upload (PDF, DOCX, TXT)
- âœ… RAG-based Question Answering
- âœ… Local LLM (No OpenAI API Required)
- âœ… Persistent FAISS Vector Store
- âœ… Voice Input
- âœ… Voice Output
- âœ… Clear / Reset Session
- âœ… REST API with FastAPI
- âœ… Modular Backend Architecture

---

## ğŸ“‚ Project Structure

```
AI-Document-Intelligence/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api.py
â”‚   â”œâ”€â”€ rag_engine.py
â”‚   â”œâ”€â”€ document_loader.py
â”‚   â”œâ”€â”€ embedding_loader.py
â”‚   â”œâ”€â”€ llm_loader.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ tts.py
â”‚   â””â”€â”€ vector_store/
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample.pdf
â”‚
â””â”€â”€ requirements.txt
```

---

## ğŸš€ Installation

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/your-username/ai-document-intelligence.git
cd ai-document-intelligence
```

---

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
```

Activate:

**Windows**
```bash
venv\Scripts\activate
```

**Mac/Linux**
```bash
source venv/bin/activate
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Running the Application

### ğŸ”¹ Start Backend (FastAPI)

```bash
cd backend
uvicorn api:app --reload
```

Backend runs at:

```
http://127.0.0.1:8000
```

Swagger API Docs:

```
http://127.0.0.1:8000/docs
```

---

### ğŸ”¹ Start Frontend (Streamlit)

```bash
cd frontend
streamlit run app.py
```

Frontend runs at:

```
http://localhost:8501
```

---

## ğŸ§ª How It Works

1. User uploads document  
2. Text is extracted  
3. Text is chunked  
4. Embeddings are generated  
5. FAISS builds vector index  
6. On question:
   - Relevant chunks retrieved  
   - Context + question sent to LLM  
   - Answer generated  
   - Voice output returned  

---

## ğŸ§© RAG Configuration

Located in `backend/config.py`:

```python
CHUNK_SIZE = 800
CHUNK_OVERLAP = 100
TOP_K = 4
MAX_NEW_TOKENS = 150
```

---

## ğŸ“ˆ Performance

- Fully local inference
- No paid APIs
- Fast response time on CPU
- Persistent vector database
- Lightweight models optimized for performance

---

## ğŸ”® Future Improvements

- Chat memory with contextual awareness
- Streaming responses
- Better LLM (Mistral / Phi-2)
- Docker deployment
- Cloud deployment (AWS / GCP)
- Authentication system

---

## ğŸ‘¨â€ğŸ’» Author

**Chandan Kheto**  
AI/ML & Generative AI Engineer  

---

## â­ Support

If you like this project, give it a â­ on GitHub!

---

